{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain-based Question Answering System\n",
    "\n",
    "This notebook implements a sophisticated question-answering system using LangChain and a fine-tuned language model. Here's a high-level overview of the main components and processes:\n",
    "\n",
    "1. **Model and Dataset Setup:**\n",
    "   - The system is designed to work with two dataset types: 'sleep' and 'cars'.\n",
    "   - A pre-trained language model (fine-tuned Llama 3.2 1B) is used as the base for question answering.\n",
    "\n",
    "2. **Prompt Engineering:**\n",
    "   - Different prompt templates are defined for each dataset type, including a system prompt and two types of user prompts: basic and RAG (Retrieval-Augmented Generation).\n",
    "   - The RAG prompt incorporates additional context (\"resources\") to enhance the model's responses.\n",
    "\n",
    "3. **LangChain Integration:**\n",
    "   - The notebook utilizes LangChain's components such as HuggingFacePipeline, LLMChain, and PromptTemplate to create a structured pipeline for processing queries and generating responses.\n",
    "\n",
    "4. **Retrieval-Augmented Generation (RAG):**\n",
    "   - The system implements a RAG approach, where relevant information is retrieved from a knowledge base and incorporated into the prompt to provide more accurate and contextual answers.\n",
    "\n",
    "5. **Dataset Processing:**\n",
    "   - The notebook includes code for handling datasets, possibly for training, evaluation, or as a source of information for the RAG system.\n",
    "\n",
    "6. **Model Configuration:**\n",
    "   - The language model is configured with specific parameters such as maximum sequence length and new token generation limits to optimize performance and output quality.\n",
    "\n",
    "This notebook essentially creates a flexible and powerful question-answering system that can adapt to different domains (sleep science or automobile history) and leverage external knowledge to provide informative responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stepan/.conda/envs/llm-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import transformers  # type: ignore\n",
    "\n",
    "from tqdm.auto import tqdm  # type: ignore\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline  # type: ignore\n",
    "from langchain.chains import LLMChain  # type: ignore\n",
    "from langchain.prompts import PromptTemplate  # type: ignore\n",
    "\n",
    "from datasets import Dataset, DatasetDict  # type: ignore\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'sleep'\n",
    "PROMPT_MODE = 'rag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/stepan/cars-sleep-chatbot\"\n",
    "MODEL_ID = f\"{BASE_PATH}/models/{dataset_type}/llama-3_2-1b-it\"\n",
    "MAX_NEW_TOKENS = 8192\n",
    "MAX_SEQ_LENGTH = 32768 - MAX_NEW_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    'cars': {\n",
    "        'system': \"You are an expert in sleep science with in-depth knowledge of sleep physiology, circadian rhythms, sleep disorders, and the impact of sleep on health and cognitive performance. Your task is to generate insightful and varied answers on sleep-related topics. The answers should be diverse in complexity, suitable for learners and experts alike.\",\n",
    "        'basic': \"Human: Generate me an answer to the given question: {question}\\n\\nAssistant:\",\n",
    "        'rag': \"Use resources provided to answer the following question.\\nResources: {resources}\\n\\nHuman: Generate me an answer to the given question: {question}\\n\\nAssistant:\",\n",
    "    },\n",
    "    'sleep': {\n",
    "        'system': \"You are an expert in the history of automobiles with in-depth knowledge of the development of automobiles from the late 19th century to the present day. Your task is to generate insightful and varied answers on automobile history. The answers should be diverse in complexity, suitable for learners and experts alike.\",\n",
    "        'basic': \"Human: Generate me an answer to the given question: {question}\\n\\nAssistant:\",\n",
    "        'rag': \"Use resources provided to answer the following question.\\nResources: {resources}\\n\\nHuman: Generate me an answer to the given question: {question}\\n\\nAssistant:\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=MODEL_ID,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"resources\"],\n",
    "    template=PROMPTS[dataset_type][PROMPT_MODE],\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llama_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_dataset(data):\n",
    "    restructured_data = {\n",
    "        \"question\": [],\n",
    "        \"resources\": [],\n",
    "        \"answer\": [],\n",
    "    }\n",
    "\n",
    "    for qna in data:\n",
    "        restructured_data[\"question\"].append(qna[\"question\"])\n",
    "        restructured_data[\"answer\"].append(qna[\"answer\"])\n",
    "        restructured_data[\"resources\"].append('\\n'.join([resource['summary'] for resource in qna[\"citation\"]]))\n",
    "\n",
    "    return Dataset.from_dict(restructured_data)\n",
    "\n",
    "\n",
    "def prepare_dataset(base_path=None):\n",
    "    test_cars = load_data(f\"{base_path}/data/test_qa_car.json\")\n",
    "    test_sleep = load_data(f\"{base_path}/data/test_qa_sleep.json\")\n",
    "\n",
    "    test_cars_dataset = to_dataset(test_cars)\n",
    "    test_sleep_dataset = to_dataset(test_sleep)\n",
    "\n",
    "    return {\"cars\": test_cars_dataset, \"sleep\": test_sleep_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(base_path=BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for question in tqdm(dataset[dataset_type][\"question\"]):\n",
    "    predictions.append(llm_chain.invoke({\"question\": question}))\n",
    "# save predictions\n",
    "with open(f\"{BASE_PATH}/data/{dataset_type}_predictions.json\", \"w\") as f:\n",
    "    json.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test without RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/stepan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader # type: ignore\n",
    "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter # type: ignore\n",
    "from langchain.vectorstores import FAISS # type: ignore\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings  # type: ignore\n",
    "from langchain.schema.runnable import RunnablePassthrough # type: ignore\n",
    "from langchain.schema import Document # type: ignore\n",
    "import nltk # type: ignore\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(f\"{BASE_PATH}/data/{dataset_type}.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 1\n",
      "Length of the first document: 273058\n",
      "First 100 characters of the document: Yawning and an Introduction to Sleep Yawn. There, I said it. And I even provided an image (ﬁgure I.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents loaded: {len(docs)}\")\n",
    "print(f\"Length of the first document: {len(docs[0].page_content)}\")\n",
    "print(f\"First 100 characters of the document: {docs[0].page_content[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 337, which is longer than the specified 250\n",
      "Created a chunk of size 360, which is longer than the specified 250\n",
      "Created a chunk of size 316, which is longer than the specified 250\n",
      "Created a chunk of size 255, which is longer than the specified 250\n",
      "Created a chunk of size 382, which is longer than the specified 250\n",
      "Created a chunk of size 293, which is longer than the specified 250\n",
      "Created a chunk of size 565, which is longer than the specified 250\n",
      "Created a chunk of size 313, which is longer than the specified 250\n",
      "Created a chunk of size 275, which is longer than the specified 250\n",
      "Created a chunk of size 273, which is longer than the specified 250\n",
      "Created a chunk of size 311, which is longer than the specified 250\n",
      "Created a chunk of size 275, which is longer than the specified 250\n",
      "Created a chunk of size 363, which is longer than the specified 250\n",
      "Created a chunk of size 262, which is longer than the specified 250\n",
      "Created a chunk of size 301, which is longer than the specified 250\n",
      "Created a chunk of size 352, which is longer than the specified 250\n",
      "Created a chunk of size 251, which is longer than the specified 250\n",
      "Created a chunk of size 409, which is longer than the specified 250\n",
      "Created a chunk of size 367, which is longer than the specified 250\n",
      "Created a chunk of size 307, which is longer than the specified 250\n",
      "Created a chunk of size 258, which is longer than the specified 250\n",
      "Created a chunk of size 310, which is longer than the specified 250\n",
      "Created a chunk of size 329, which is longer than the specified 250\n",
      "Created a chunk of size 363, which is longer than the specified 250\n",
      "Created a chunk of size 268, which is longer than the specified 250\n",
      "Created a chunk of size 391, which is longer than the specified 250\n",
      "Created a chunk of size 262, which is longer than the specified 250\n",
      "Created a chunk of size 329, which is longer than the specified 250\n",
      "Created a chunk of size 253, which is longer than the specified 250\n",
      "Created a chunk of size 909, which is longer than the specified 250\n",
      "Created a chunk of size 331, which is longer than the specified 250\n",
      "Created a chunk of size 267, which is longer than the specified 250\n",
      "Created a chunk of size 256, which is longer than the specified 250\n",
      "Created a chunk of size 260, which is longer than the specified 250\n",
      "Created a chunk of size 270, which is longer than the specified 250\n",
      "Created a chunk of size 264, which is longer than the specified 250\n",
      "Created a chunk of size 268, which is longer than the specified 250\n",
      "Created a chunk of size 278, which is longer than the specified 250\n",
      "Created a chunk of size 270, which is longer than the specified 250\n",
      "Created a chunk of size 471, which is longer than the specified 250\n",
      "Created a chunk of size 280, which is longer than the specified 250\n",
      "Created a chunk of size 318, which is longer than the specified 250\n",
      "Created a chunk of size 268, which is longer than the specified 250\n",
      "Created a chunk of size 367, which is longer than the specified 250\n",
      "Created a chunk of size 252, which is longer than the specified 250\n",
      "Created a chunk of size 285, which is longer than the specified 250\n",
      "Created a chunk of size 272, which is longer than the specified 250\n",
      "Created a chunk of size 295, which is longer than the specified 250\n",
      "Created a chunk of size 404, which is longer than the specified 250\n",
      "Created a chunk of size 488, which is longer than the specified 250\n",
      "Created a chunk of size 636, which is longer than the specified 250\n",
      "Created a chunk of size 450, which is longer than the specified 250\n",
      "Created a chunk of size 289, which is longer than the specified 250\n",
      "Created a chunk of size 255, which is longer than the specified 250\n",
      "Created a chunk of size 289, which is longer than the specified 250\n",
      "Created a chunk of size 298, which is longer than the specified 250\n",
      "Created a chunk of size 286, which is longer than the specified 250\n",
      "Created a chunk of size 254, which is longer than the specified 250\n",
      "Created a chunk of size 274, which is longer than the specified 250\n",
      "Created a chunk of size 288, which is longer than the specified 250\n",
      "Created a chunk of size 312, which is longer than the specified 250\n",
      "Created a chunk of size 354, which is longer than the specified 250\n",
      "Created a chunk of size 261, which is longer than the specified 250\n",
      "Created a chunk of size 290, which is longer than the specified 250\n",
      "Created a chunk of size 286, which is longer than the specified 250\n",
      "Created a chunk of size 304, which is longer than the specified 250\n",
      "Created a chunk of size 347, which is longer than the specified 250\n",
      "Created a chunk of size 257, which is longer than the specified 250\n",
      "Created a chunk of size 281, which is longer than the specified 250\n",
      "Created a chunk of size 446, which is longer than the specified 250\n",
      "Created a chunk of size 277, which is longer than the specified 250\n",
      "Created a chunk of size 254, which is longer than the specified 250\n",
      "Created a chunk of size 267, which is longer than the specified 250\n",
      "Created a chunk of size 264, which is longer than the specified 250\n",
      "Created a chunk of size 308, which is longer than the specified 250\n",
      "Created a chunk of size 262, which is longer than the specified 250\n",
      "Created a chunk of size 311, which is longer than the specified 250\n",
      "Created a chunk of size 264, which is longer than the specified 250\n",
      "Created a chunk of size 300, which is longer than the specified 250\n",
      "Created a chunk of size 308, which is longer than the specified 250\n",
      "Created a chunk of size 684, which is longer than the specified 250\n",
      "Created a chunk of size 262, which is longer than the specified 250\n",
      "Created a chunk of size 333, which is longer than the specified 250\n",
      "Created a chunk of size 276, which is longer than the specified 250\n",
      "Created a chunk of size 362, which is longer than the specified 250\n",
      "Created a chunk of size 328, which is longer than the specified 250\n",
      "Created a chunk of size 327, which is longer than the specified 250\n",
      "Created a chunk of size 286, which is longer than the specified 250\n",
      "Created a chunk of size 255, which is longer than the specified 250\n",
      "Created a chunk of size 490, which is longer than the specified 250\n",
      "Created a chunk of size 322, which is longer than the specified 250\n",
      "Created a chunk of size 409, which is longer than the specified 250\n",
      "Created a chunk of size 410, which is longer than the specified 250\n",
      "Created a chunk of size 381, which is longer than the specified 250\n",
      "Created a chunk of size 266, which is longer than the specified 250\n",
      "Created a chunk of size 279, which is longer than the specified 250\n",
      "Created a chunk of size 658, which is longer than the specified 250\n",
      "Created a chunk of size 290, which is longer than the specified 250\n",
      "Created a chunk of size 253, which is longer than the specified 250\n",
      "Created a chunk of size 329, which is longer than the specified 250\n",
      "Created a chunk of size 286, which is longer than the specified 250\n",
      "Created a chunk of size 355, which is longer than the specified 250\n",
      "Created a chunk of size 293, which is longer than the specified 250\n",
      "Created a chunk of size 554, which is longer than the specified 250\n",
      "Created a chunk of size 258, which is longer than the specified 250\n",
      "Created a chunk of size 265, which is longer than the specified 250\n",
      "Created a chunk of size 583, which is longer than the specified 250\n",
      "Created a chunk of size 321, which is longer than the specified 250\n",
      "Created a chunk of size 307, which is longer than the specified 250\n",
      "Created a chunk of size 340, which is longer than the specified 250\n",
      "Created a chunk of size 319, which is longer than the specified 250\n",
      "Created a chunk of size 258, which is longer than the specified 250\n",
      "Created a chunk of size 251, which is longer than the specified 250\n",
      "Created a chunk of size 339, which is longer than the specified 250\n",
      "Created a chunk of size 283, which is longer than the specified 250\n",
      "Created a chunk of size 398, which is longer than the specified 250\n",
      "Created a chunk of size 278, which is longer than the specified 250\n",
      "Created a chunk of size 251, which is longer than the specified 250\n",
      "Created a chunk of size 323, which is longer than the specified 250\n",
      "Created a chunk of size 283, which is longer than the specified 250\n",
      "Created a chunk of size 277, which is longer than the specified 250\n",
      "Created a chunk of size 342, which is longer than the specified 250\n",
      "Created a chunk of size 624, which is longer than the specified 250\n",
      "Created a chunk of size 326, which is longer than the specified 250\n",
      "Created a chunk of size 268, which is longer than the specified 250\n",
      "Created a chunk of size 366, which is longer than the specified 250\n",
      "Created a chunk of size 264, which is longer than the specified 250\n",
      "Created a chunk of size 381, which is longer than the specified 250\n",
      "Created a chunk of size 278, which is longer than the specified 250\n",
      "Created a chunk of size 265, which is longer than the specified 250\n",
      "Created a chunk of size 387, which is longer than the specified 250\n",
      "Created a chunk of size 373, which is longer than the specified 250\n",
      "Created a chunk of size 305, which is longer than the specified 250\n",
      "Created a chunk of size 416, which is longer than the specified 250\n",
      "Created a chunk of size 268, which is longer than the specified 250\n",
      "Created a chunk of size 407, which is longer than the specified 250\n",
      "Created a chunk of size 566, which is longer than the specified 250\n",
      "Created a chunk of size 510, which is longer than the specified 250\n",
      "Created a chunk of size 288, which is longer than the specified 250\n",
      "Created a chunk of size 325, which is longer than the specified 250\n",
      "Created a chunk of size 364, which is longer than the specified 250\n",
      "Created a chunk of size 395, which is longer than the specified 250\n",
      "Created a chunk of size 623, which is longer than the specified 250\n",
      "Created a chunk of size 6175, which is longer than the specified 250\n",
      "Created a chunk of size 465, which is longer than the specified 250\n",
      "Created a chunk of size 368, which is longer than the specified 250\n",
      "Created a chunk of size 409, which is longer than the specified 250\n",
      "Created a chunk of size 602, which is longer than the specified 250\n",
      "Created a chunk of size 632, which is longer than the specified 250\n",
      "Created a chunk of size 1073, which is longer than the specified 250\n",
      "Created a chunk of size 720, which is longer than the specified 250\n",
      "Created a chunk of size 1269, which is longer than the specified 250\n",
      "Created a chunk of size 686, which is longer than the specified 250\n",
      "Created a chunk of size 454, which is longer than the specified 250\n",
      "Created a chunk of size 399, which is longer than the specified 250\n",
      "Created a chunk of size 509, which is longer than the specified 250\n",
      "Created a chunk of size 315, which is longer than the specified 250\n"
     ]
    }
   ],
   "source": [
    "text_splitter = NLTKTextSplitter(chunk_size=250, chunk_overlap=20)\n",
    "chunked_documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in chunked_documents:\n",
    "    doc.metadata['dataset_type'] = dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(chunked_documents, HuggingFaceEmbeddings(model_name='sentence-transformers/multi-qa-MiniLM-L6-dot-v1'))\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 4, 'score_threshold': 0.5},\n",
    "    filter={'dataset_type': dataset_type}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ( {\"resources\": retriever | format_docs, \"question\": RunnablePassthrough()} | llm_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      " 37%|███▋      | 10/27 [02:45<04:02, 14.24s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 27/27 [07:50<00:00, 17.41s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for question in tqdm(dataset[dataset_type][\"question\"]):\n",
    "    predictions.append(rag_chain.invoke(question))\n",
    "# save predictions\n",
    "with open(f\"{BASE_PATH}/data/{dataset_type}_rag_predictions.json\", \"w\") as f:\n",
    "    json.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
